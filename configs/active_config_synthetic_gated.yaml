defaults:
  - _self_
  - model: probabilistic # Your existing model default

training:
  num_epochs: 1
  lr: 1e-4
  eval_steps: 1000
  max_num_eval_steps: 10
  seed: 42
  dry_run: False         # Set to true to skip wandb logging and saving
  num_episodes: 100
  acquisition_function: uniform
  num_acquired_samples: 320
  num_initial_samples: 1000
  buffer_type: fifo
  buffer_capacity: 50000
  buffer_ratio: 0.8
  training_mode: "joint"   # options: joint | sequential | pretrain_joint
  cp_epochs: 10
  j_epochs: 20
  s_epochs: 10
  active_learning: true


loss:
  beta_concept: 1.0              # Weight for concept_loss in total loss
  beta_kl: 0.001
  beta_temperature: 0.001
save:
  project_name: May20
  wandb_entity: interp_rewards_RLHF
  run_name_prefix: active_learning_crm

data:
  embeddings_path: ./datasets/synthetic_cbm_data/embeddings
  splits_path: ./datasets/synthetic_cbm_data/splits.csv
  concept_labels_path: ./datasets/synthetic_cbm_data/concept_labels_gated
  preference_labels_path: ./datasets/synthetic_cbm_data/preference_labels_gated
  batch_size: 32
 
resolve_model_target:
  deterministic: src.models.reward_models.BottleneckRewardModel
  probabilistic: src.models.reward_models.ProbabilisticBottleneckRewardModel

train_dataset:
  _target_: src.data.dataloaders.ExpandableConceptPreferenceDataset
  embeddings_path: ${data.embeddings_path}
  splits_path: ${data.splits_path}
  concept_labels_path: ${data.concept_labels_path}
  preference_labels_path: ${data.preference_labels_path}
  split: train
  random_init: True
  num_initial_samples: ${training.num_initial_samples}

val_dataloader:
  _target_: src.data.dataloaders.get_dataloader
  cfg: ${data}
  split: val

